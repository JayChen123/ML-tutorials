{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手动实现简单的神经网络\n",
    "本节内容我们手动实现一个简单的神经网络，不使用任何深度学习框架。目的在于**理解深度学习的原理**，包括参数的前向传递和反向传递。反向传播的过程使用梯度下降算法来更新参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载数据集\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (404,), (102, 13), (102,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造参数\n",
    "这里定义输入层和输出层，不定义隐藏层参数，相当于是一个多元线性回归的问题。\n",
    "1. 输入数据有13个特征，就有13个w参数\n",
    "2. 输出只有一个维度，所以参w数的shape为13x1，加上一个偏置b\n",
    "\n",
    "总的参数量为14个，没有激活层。boston_housing数据是根据13个特征来预测房价，这是一个典型的回归问题。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化参数\n",
    "w = np.random.rand(13, 1)\n",
    "b = np.random.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前向传播过程计算参数与权重的乘积， 直到输出最终的预测结果。$$\\hat y = wx+b$$ 其中$\\hat y$就是最终的输出结果。接下来计算误差，我们采用MSE（平均平方误差）。总的误差E作为全部样本的误差和的平均值。 $$ E = \\frac {1} {2m} \\sum_{i=1}^m (\\hat y_i - y_i) ^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_y = np.dot(x_train, w) + b * np.ones_like(x_train.shape[0]) # hat_y.shape = (404, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = hat_y - y_train.reshape(-1, 1) # (404, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 反向传播\n",
    "\n",
    "参数$w, b$取值，使得总的误差E最小。我们采用梯度下降算法来计算参数。\n",
    "\n",
    "$$ \\Delta w = \\gamma \\frac{\\partial E}{\\partial w} $$\n",
    "$$ \\Delta b = \\gamma \\frac{\\partial E}{\\partial b} $$\n",
    "\n",
    "$$ w \\leftarrow w -  \\Delta w $$\n",
    "$$ b \\leftarrow b -  \\Delta b $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度下降算法的关键在于计算梯度值，接下来推导一下梯度的计算过程。\n",
    "\n",
    "$$ \\frac{\\partial E}{\\partial w_j} = \\sum_{i=1} ^m \\frac{\\partial E}{\\partial \\hat y_i} \\frac{\\partial \\hat y_i}{\\partial w_j} \\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial E}{\\partial \\hat y_i} = \\frac 1 m (\\hat y_i - y_i)$$\n",
    "$$ \\frac{\\partial \\hat y_i}{\\partial w_j} = x_j $$\n",
    "\n",
    "同理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial E}{\\partial b} =  \\frac 1 m \\sum_{i=1}^m (\\hat y_i - y_i) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 500000\n",
    "lr = 1e-6\n",
    "m = x_train.shape[0] # 样本量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \t loss: 10295627.992053345\n",
      "epoch: 1000 \t loss: 45310.45611735715\n",
      "epoch: 2000 \t loss: 36517.299120095224\n",
      "epoch: 3000 \t loss: 31457.156618423713\n",
      "epoch: 4000 \t loss: 28236.034005940983\n",
      "epoch: 5000 \t loss: 26006.0726613328\n",
      "epoch: 6000 \t loss: 24341.45202293557\n",
      "epoch: 7000 \t loss: 23016.546603254064\n",
      "epoch: 8000 \t loss: 21908.29141260578\n",
      "epoch: 9000 \t loss: 20947.89059524959\n",
      "epoch: 10000 \t loss: 20095.70479014146\n",
      "epoch: 11000 \t loss: 19327.932217213856\n",
      "epoch: 12000 \t loss: 18629.485381561164\n",
      "epoch: 13000 \t loss: 17990.16195125253\n",
      "epoch: 14000 \t loss: 17402.575518984006\n",
      "epoch: 15000 \t loss: 16861.02891043295\n",
      "epoch: 16000 \t loss: 16360.893412253867\n",
      "epoch: 17000 \t loss: 15898.260368855088\n",
      "epoch: 18000 \t loss: 15469.740101531923\n",
      "epoch: 19000 \t loss: 15072.341118734606\n",
      "epoch: 20000 \t loss: 14703.393619605496\n",
      "epoch: 21000 \t loss: 14360.497901221157\n",
      "epoch: 22000 \t loss: 14041.487174680358\n",
      "epoch: 23000 \t loss: 13744.3990643156\n",
      "epoch: 24000 \t loss: 13467.45262628786\n",
      "epoch: 25000 \t loss: 13209.029103461347\n",
      "epoch: 26000 \t loss: 12967.655381328314\n",
      "epoch: 27000 \t loss: 12741.98951828279\n",
      "epoch: 28000 \t loss: 12530.807949713484\n",
      "epoch: 29000 \t loss: 12332.99409323206\n",
      "epoch: 30000 \t loss: 12147.528156889552\n",
      "epoch: 31000 \t loss: 11973.477997608457\n",
      "epoch: 32000 \t loss: 11809.990906251682\n",
      "epoch: 33000 \t loss: 11656.286215766235\n",
      "epoch: 34000 \t loss: 11511.648643479639\n",
      "epoch: 35000 \t loss: 11375.422289973709\n",
      "epoch: 36000 \t loss: 11247.005226171492\n",
      "epoch: 37000 \t loss: 11125.844608008583\n",
      "epoch: 38000 \t loss: 11011.432264708092\n",
      "epoch: 39000 \t loss: 10903.300712478598\n",
      "epoch: 40000 \t loss: 10801.019550563573\n",
      "epoch: 41000 \t loss: 10704.192201097638\n",
      "epoch: 42000 \t loss: 10612.452958251248\n",
      "epoch: 43000 \t loss: 10525.464315734207\n",
      "epoch: 44000 \t loss: 10442.914544932071\n",
      "epoch: 45000 \t loss: 10364.515498812067\n",
      "epoch: 46000 \t loss: 10290.000619294413\n",
      "epoch: 47000 \t loss: 10219.12312807413\n",
      "epoch: 48000 \t loss: 10151.654382926976\n",
      "epoch: 49000 \t loss: 10087.38238336617\n",
      "epoch: 50000 \t loss: 10026.11041115842\n",
      "epoch: 51000 \t loss: 9967.655792677098\n",
      "epoch: 52000 \t loss: 9911.848771387344\n",
      "epoch: 53000 \t loss: 9858.531479937214\n",
      "epoch: 54000 \t loss: 9807.557002385925\n",
      "epoch: 55000 \t loss: 9758.788518047837\n",
      "epoch: 56000 \t loss: 9712.098519280164\n",
      "epoch: 57000 \t loss: 9667.368096304337\n",
      "epoch: 58000 \t loss: 9624.486282834236\n",
      "epoch: 59000 \t loss: 9583.34945689794\n",
      "epoch: 60000 \t loss: 9543.860791789977\n",
      "epoch: 61000 \t loss: 9505.929752585398\n",
      "epoch: 62000 \t loss: 9469.471634091002\n",
      "epoch: 63000 \t loss: 9434.407136507816\n",
      "epoch: 64000 \t loss: 9400.661975437564\n",
      "epoch: 65000 \t loss: 9368.166523188182\n",
      "epoch: 66000 \t loss: 9336.855478623482\n",
      "epoch: 67000 \t loss: 9306.667563062856\n",
      "epoch: 68000 \t loss: 9277.545239971985\n",
      "epoch: 69000 \t loss: 9249.434456396895\n",
      "epoch: 70000 \t loss: 9222.28440428448\n",
      "epoch: 71000 \t loss: 9196.047300004182\n",
      "epoch: 72000 \t loss: 9170.678180540734\n",
      "epoch: 73000 \t loss: 9146.134714967407\n",
      "epoch: 74000 \t loss: 9122.37702993563\n",
      "epoch: 75000 \t loss: 9099.367548030554\n",
      "epoch: 76000 \t loss: 9077.070837945437\n",
      "epoch: 77000 \t loss: 9055.45347552052\n",
      "epoch: 78000 \t loss: 9034.483914776582\n",
      "epoch: 79000 \t loss: 9014.13236814933\n",
      "epoch: 80000 \t loss: 8994.370695200163\n",
      "epoch: 81000 \t loss: 8975.172299141024\n",
      "epoch: 82000 \t loss: 8956.51203056815\n",
      "epoch: 83000 \t loss: 8938.366097850778\n",
      "epoch: 84000 \t loss: 8920.711983667708\n",
      "epoch: 85000 \t loss: 8903.528367227074\n",
      "epoch: 86000 \t loss: 8886.795051743185\n",
      "epoch: 87000 \t loss: 8870.492896779542\n",
      "epoch: 88000 \t loss: 8854.603755098984\n",
      "epoch: 89000 \t loss: 8839.110413691105\n",
      "epoch: 90000 \t loss: 8823.996538673531\n",
      "epoch: 91000 \t loss: 8809.246623787953\n",
      "epoch: 92000 \t loss: 8794.845942233822\n",
      "epoch: 93000 \t loss: 8780.780501602861\n",
      "epoch: 94000 \t loss: 8767.037001695891\n",
      "epoch: 95000 \t loss: 8753.60279502048\n",
      "epoch: 96000 \t loss: 8740.46584978324\n",
      "epoch: 97000 \t loss: 8727.61471520484\n",
      "epoch: 98000 \t loss: 8715.038488998693\n",
      "epoch: 99000 \t loss: 8702.726786866253\n",
      "epoch: 100000 \t loss: 8690.669713872694\n",
      "epoch: 101000 \t loss: 8678.857837576867\n",
      "epoch: 102000 \t loss: 8667.282162798538\n",
      "epoch: 103000 \t loss: 8655.934107914542\n",
      "epoch: 104000 \t loss: 8644.805482583171\n",
      "epoch: 105000 \t loss: 8633.888466803324\n",
      "epoch: 106000 \t loss: 8623.175591221707\n",
      "epoch: 107000 \t loss: 8612.659718607287\n",
      "epoch: 108000 \t loss: 8602.334026418048\n",
      "epoch: 109000 \t loss: 8592.19199039013\n",
      "epoch: 110000 \t loss: 8582.227369084485\n",
      "epoch: 111000 \t loss: 8572.434189330299\n",
      "epoch: 112000 \t loss: 8562.806732508996\n",
      "epoch: 113000 \t loss: 8553.33952162603\n",
      "epoch: 114000 \t loss: 8544.027309121515\n",
      "epoch: 115000 \t loss: 8534.865065373879\n",
      "epoch: 116000 \t loss: 8525.847967853842\n",
      "epoch: 117000 \t loss: 8516.971390888742\n",
      "epoch: 118000 \t loss: 8508.230896000026\n",
      "epoch: 119000 \t loss: 8499.622222778964\n",
      "epoch: 120000 \t loss: 8491.141280268077\n",
      "epoch: 121000 \t loss: 8482.784138817793\n",
      "epoch: 122000 \t loss: 8474.547022389794\n",
      "epoch: 123000 \t loss: 8466.426301280408\n",
      "epoch: 124000 \t loss: 8458.418485239075\n",
      "epoch: 125000 \t loss: 8450.520216958419\n",
      "epoch: 126000 \t loss: 8442.728265914098\n",
      "epoch: 127000 \t loss: 8435.039522533849\n",
      "epoch: 128000 \t loss: 8427.450992676457\n",
      "epoch: 129000 \t loss: 8419.959792402657\n",
      "epoch: 130000 \t loss: 8412.563143020923\n",
      "epoch: 131000 \t loss: 8405.258366392427\n",
      "epoch: 132000 \t loss: 8398.042880480061\n",
      "epoch: 133000 \t loss: 8390.914195127716\n",
      "epoch: 134000 \t loss: 8383.869908056535\n",
      "epoch: 135000 \t loss: 8376.90770106588\n",
      "epoch: 136000 \t loss: 8370.025336427414\n",
      "epoch: 137000 \t loss: 8363.220653461376\n",
      "epoch: 138000 \t loss: 8356.49156528484\n",
      "epoch: 139000 \t loss: 8349.836055722351\n",
      "epoch: 140000 \t loss: 8343.252176369839\n",
      "epoch: 141000 \t loss: 8336.738043803367\n",
      "epoch: 142000 \t loss: 8330.291836924696\n",
      "epoch: 143000 \t loss: 8323.911794436095\n",
      "epoch: 144000 \t loss: 8317.596212437371\n",
      "epoch: 145000 \t loss: 8311.343442138437\n",
      "epoch: 146000 \t loss: 8305.15188768111\n",
      "epoch: 147000 \t loss: 8299.020004064301\n",
      "epoch: 148000 \t loss: 8292.946295166923\n",
      "epoch: 149000 \t loss: 8286.9293118634\n",
      "epoch: 150000 \t loss: 8280.967650226761\n",
      "epoch: 151000 \t loss: 8275.059949814658\n",
      "epoch: 152000 \t loss: 8269.204892034002\n",
      "epoch: 153000 \t loss: 8263.401198579979\n",
      "epoch: 154000 \t loss: 8257.647629945637\n",
      "epoch: 155000 \t loss: 8251.942983998313\n",
      "epoch: 156000 \t loss: 8246.286094619458\n",
      "epoch: 157000 \t loss: 8240.675830404583\n",
      "epoch: 158000 \t loss: 8235.111093420255\n",
      "epoch: 159000 \t loss: 8229.590818015182\n",
      "epoch: 160000 \t loss: 8224.113969682716\n",
      "epoch: 161000 \t loss: 8218.6795439721\n",
      "epoch: 162000 \t loss: 8213.286565446073\n",
      "epoch: 163000 \t loss: 8207.934086682453\n",
      "epoch: 164000 \t loss: 8202.621187317598\n",
      "epoch: 165000 \t loss: 8197.346973129559\n",
      "epoch: 166000 \t loss: 8192.110575159115\n",
      "epoch: 167000 \t loss: 8186.911148866713\n",
      "epoch: 168000 \t loss: 8181.747873323649\n",
      "epoch: 169000 \t loss: 8176.619950435815\n",
      "epoch: 170000 \t loss: 8171.526604198434\n",
      "epoch: 171000 \t loss: 8166.467079980347\n",
      "epoch: 172000 \t loss: 8161.440643836402\n",
      "epoch: 173000 \t loss: 8156.446581846671\n",
      "epoch: 174000 \t loss: 8151.484199481212\n",
      "epoch: 175000 \t loss: 8146.552820989191\n",
      "epoch: 176000 \t loss: 8141.651788811251\n",
      "epoch: 177000 \t loss: 8136.78046301408\n",
      "epoch: 178000 \t loss: 8131.9382207461185\n",
      "epoch: 179000 \t loss: 8127.124455713491\n",
      "epoch: 180000 \t loss: 8122.338577675254\n",
      "epoch: 181000 \t loss: 8117.580011957089\n",
      "epoch: 182000 \t loss: 8112.848198982617\n",
      "epoch: 183000 \t loss: 8108.1425938215725\n",
      "epoch: 184000 \t loss: 8103.462665754114\n",
      "epoch: 185000 \t loss: 8098.807897850548\n",
      "epoch: 186000 \t loss: 8094.177786565815\n",
      "epoch: 187000 \t loss: 8089.571841348121\n",
      "epoch: 188000 \t loss: 8084.989584261096\n",
      "epoch: 189000 \t loss: 8080.430549618921\n",
      "epoch: 190000 \t loss: 8075.894283633904\n",
      "epoch: 191000 \t loss: 8071.380344075929\n",
      "epoch: 192000 \t loss: 8066.888299943383\n",
      "epoch: 193000 \t loss: 8062.417731144997\n",
      "epoch: 194000 \t loss: 8057.968228192236\n",
      "epoch: 195000 \t loss: 8053.539391901792\n",
      "epoch: 196000 \t loss: 8049.130833107739\n",
      "epoch: 197000 \t loss: 8044.742172383038\n",
      "epoch: 198000 \t loss: 8040.373039769977\n",
      "epoch: 199000 \t loss: 8036.023074519219\n",
      "epoch: 200000 \t loss: 8031.691924837105\n",
      "epoch: 201000 \t loss: 8027.379247640946\n",
      "epoch: 202000 \t loss: 8023.084708321949\n",
      "epoch: 203000 \t loss: 8018.807980515486\n",
      "epoch: 204000 \t loss: 8014.548745878521\n",
      "epoch: 205000 \t loss: 8010.3066938738075\n",
      "epoch: 206000 \t loss: 8006.081521560667\n",
      "epoch: 207000 \t loss: 8001.872933392173\n",
      "epoch: 208000 \t loss: 7997.680641018364\n",
      "epoch: 209000 \t loss: 7993.504363095394\n",
      "epoch: 210000 \t loss: 7989.343825100348\n",
      "epoch: 211000 \t loss: 7985.198759151564\n",
      "epoch: 212000 \t loss: 7981.068903834221\n",
      "epoch: 213000 \t loss: 7976.954004031025\n",
      "epoch: 214000 \t loss: 7972.8538107578615\n",
      "epoch: 215000 \t loss: 7968.768081004186\n",
      "epoch: 216000 \t loss: 7964.696577577995\n",
      "epoch: 217000 \t loss: 7960.639068955271\n",
      "epoch: 218000 \t loss: 7956.5953291337355\n",
      "epoch: 219000 \t loss: 7952.565137490704\n",
      "epoch: 220000 \t loss: 7948.548278645031\n",
      "epoch: 221000 \t loss: 7944.544542322815\n",
      "epoch: 222000 \t loss: 7940.553723227027\n",
      "epoch: 223000 \t loss: 7936.5756209106385\n",
      "epoch: 224000 \t loss: 7932.610039653333\n",
      "epoch: 225000 \t loss: 7928.65678834162\n",
      "epoch: 226000 \t loss: 7924.715680352227\n",
      "epoch: 227000 \t loss: 7920.786533438716\n",
      "epoch: 228000 \t loss: 7916.8691696211645\n",
      "epoch: 229000 \t loss: 7912.96341507888\n",
      "epoch: 230000 \t loss: 7909.069100045995\n",
      "epoch: 231000 \t loss: 7905.186058709892\n",
      "epoch: 232000 \t loss: 7901.31412911237\n",
      "epoch: 233000 \t loss: 7897.45315305342\n",
      "epoch: 234000 \t loss: 7893.602975997632\n",
      "epoch: 235000 \t loss: 7889.763446983034\n",
      "epoch: 236000 \t loss: 7885.934418532412\n",
      "epoch: 237000 \t loss: 7882.115746566908\n",
      "epoch: 238000 \t loss: 7878.307290321951\n",
      "epoch: 239000 \t loss: 7874.508912265359\n",
      "epoch: 240000 \t loss: 7870.720478017631\n",
      "epoch: 241000 \t loss: 7866.941856274289\n",
      "epoch: 242000 \t loss: 7863.172918730249\n",
      "epoch: 243000 \t loss: 7859.413540006158\n",
      "epoch: 244000 \t loss: 7855.663597576666\n",
      "epoch: 245000 \t loss: 7851.922971700525\n",
      "epoch: 246000 \t loss: 7848.191545352489\n",
      "epoch: 247000 \t loss: 7844.469204156995\n",
      "epoch: 248000 \t loss: 7840.755836323511\n",
      "epoch: 249000 \t loss: 7837.051332583581\n",
      "epoch: 250000 \t loss: 7833.355586129442\n",
      "epoch: 251000 \t loss: 7829.6684925542195\n",
      "epoch: 252000 \t loss: 7825.989949793662\n",
      "epoch: 253000 \t loss: 7822.319858069321\n",
      "epoch: 254000 \t loss: 7818.658119833195\n",
      "epoch: 255000 \t loss: 7815.004639713784\n",
      "epoch: 256000 \t loss: 7811.359324463476\n",
      "epoch: 257000 \t loss: 7807.722082907273\n",
      "epoch: 258000 \t loss: 7804.092825892814\n",
      "epoch: 259000 \t loss: 7800.4714662416445\n",
      "epoch: 260000 \t loss: 7796.857918701711\n",
      "epoch: 261000 \t loss: 7793.25209990104\n",
      "epoch: 262000 \t loss: 7789.653928302577\n",
      "epoch: 263000 \t loss: 7786.063324160163\n",
      "epoch: 264000 \t loss: 7782.480209475584\n",
      "epoch: 265000 \t loss: 7778.904507956696\n",
      "epoch: 266000 \t loss: 7775.336144976614\n",
      "epoch: 267000 \t loss: 7771.775047533887\n",
      "epoch: 268000 \t loss: 7768.221144213651\n",
      "epoch: 269000 \t loss: 7764.674365149792\n",
      "epoch: 270000 \t loss: 7761.134641987964\n",
      "epoch: 271000 \t loss: 7757.601907849604\n",
      "epoch: 272000 \t loss: 7754.0760972967655\n",
      "epoch: 273000 \t loss: 7750.557146297874\n",
      "epoch: 274000 \t loss: 7747.04499219425\n",
      "epoch: 275000 \t loss: 7743.539573667552\n",
      "epoch: 276000 \t loss: 7740.040830707932\n",
      "epoch: 277000 \t loss: 7736.548704583007\n",
      "epoch: 278000 \t loss: 7733.063137807594\n",
      "epoch: 279000 \t loss: 7729.584074114169\n",
      "epoch: 280000 \t loss: 7726.111458424066\n",
      "epoch: 281000 \t loss: 7722.645236819349\n",
      "epoch: 282000 \t loss: 7719.185356515394\n",
      "epoch: 283000 \t loss: 7715.7317658341435\n",
      "epoch: 284000 \t loss: 7712.2844141779915\n",
      "epoch: 285000 \t loss: 7708.843252004292\n",
      "epoch: 286000 \t loss: 7705.4082308005345\n",
      "epoch: 287000 \t loss: 7701.979303060072\n",
      "epoch: 288000 \t loss: 7698.556422258468\n",
      "epoch: 289000 \t loss: 7695.139542830402\n",
      "epoch: 290000 \t loss: 7691.728620147129\n",
      "epoch: 291000 \t loss: 7688.323610494499\n",
      "epoch: 292000 \t loss: 7684.924471051501\n",
      "epoch: 293000 \t loss: 7681.531159869319\n",
      "epoch: 294000 \t loss: 7678.1436358508945\n",
      "epoch: 295000 \t loss: 7674.761858730997\n",
      "epoch: 296000 \t loss: 7671.38578905674\n",
      "epoch: 297000 \t loss: 7668.015388168607\n",
      "epoch: 298000 \t loss: 7664.650618181911\n",
      "epoch: 299000 \t loss: 7661.29144196869\n",
      "epoch: 300000 \t loss: 7657.937823140065\n",
      "epoch: 301000 \t loss: 7654.589726029002\n",
      "epoch: 302000 \t loss: 7651.247115673474\n",
      "epoch: 303000 \t loss: 7647.909957800076\n",
      "epoch: 304000 \t loss: 7644.57821880797\n",
      "epoch: 305000 \t loss: 7641.251865753259\n",
      "epoch: 306000 \t loss: 7637.930866333728\n",
      "epoch: 307000 \t loss: 7634.615188873915\n",
      "epoch: 308000 \t loss: 7631.304802310586\n",
      "epoch: 309000 \t loss: 7627.9996761785405\n",
      "epoch: 310000 \t loss: 7624.6997805967385\n",
      "epoch: 311000 \t loss: 7621.405086254774\n",
      "epoch: 312000 \t loss: 7618.11556439966\n",
      "epoch: 313000 \t loss: 7614.831186822967\n",
      "epoch: 314000 \t loss: 7611.551925848197\n",
      "epoch: 315000 \t loss: 7608.2777543185275\n",
      "epoch: 316000 \t loss: 7605.008645584805\n",
      "epoch: 317000 \t loss: 7601.744573493834\n",
      "epoch: 318000 \t loss: 7598.4855123769485\n",
      "epoch: 319000 \t loss: 7595.231437038854\n",
      "epoch: 320000 \t loss: 7591.982322746748\n",
      "epoch: 321000 \t loss: 7588.7381452196605\n",
      "epoch: 322000 \t loss: 7585.498880618076\n",
      "epoch: 323000 \t loss: 7582.264505533805\n",
      "epoch: 324000 \t loss: 7579.034996980079\n",
      "epoch: 325000 \t loss: 7575.810332381887\n",
      "epoch: 326000 \t loss: 7572.590489566552\n",
      "epoch: 327000 \t loss: 7569.375446754509\n",
      "epoch: 328000 \t loss: 7566.165182550301\n",
      "epoch: 329000 \t loss: 7562.95967593382\n",
      "epoch: 330000 \t loss: 7559.758906251731\n",
      "epoch: 331000 \t loss: 7556.56285320908\n",
      "epoch: 332000 \t loss: 7553.371496861137\n",
      "epoch: 333000 \t loss: 7550.184817605408\n",
      "epoch: 334000 \t loss: 7547.002796173854\n",
      "epoch: 335000 \t loss: 7543.825413625271\n",
      "epoch: 336000 \t loss: 7540.65265133786\n",
      "epoch: 337000 \t loss: 7537.484491001967\n",
      "epoch: 338000 \t loss: 7534.320914613022\n",
      "epoch: 339000 \t loss: 7531.161904464596\n",
      "epoch: 340000 \t loss: 7528.007443141656\n",
      "epoch: 341000 \t loss: 7524.857513513965\n",
      "epoch: 342000 \t loss: 7521.7120987296585\n",
      "epoch: 343000 \t loss: 7518.571182208915\n",
      "epoch: 344000 \t loss: 7515.434747637869\n",
      "epoch: 345000 \t loss: 7512.302778962551\n",
      "epoch: 346000 \t loss: 7509.175260383086\n",
      "epoch: 347000 \t loss: 7506.05217634794\n",
      "epoch: 348000 \t loss: 7502.933511548343\n",
      "epoch: 349000 \t loss: 7499.819250912836\n",
      "epoch: 350000 \t loss: 7496.709379601934\n",
      "epoch: 351000 \t loss: 7493.603883002939\n",
      "epoch: 352000 \t loss: 7490.502746724844\n",
      "epoch: 353000 \t loss: 7487.405956593379\n",
      "epoch: 354000 \t loss: 7484.31349864617\n",
      "epoch: 355000 \t loss: 7481.225359127974\n",
      "epoch: 356000 \t loss: 7478.141524486109\n",
      "epoch: 357000 \t loss: 7475.061981365894\n",
      "epoch: 358000 \t loss: 7471.986716606263\n",
      "epoch: 359000 \t loss: 7468.91571723545\n",
      "epoch: 360000 \t loss: 7465.848970466786\n",
      "epoch: 361000 \t loss: 7462.786463694592\n",
      "epoch: 362000 \t loss: 7459.728184490165\n",
      "epoch: 363000 \t loss: 7456.674120597858\n",
      "epoch: 364000 \t loss: 7453.624259931257\n",
      "epoch: 365000 \t loss: 7450.578590569439\n",
      "epoch: 366000 \t loss: 7447.537100753319\n",
      "epoch: 367000 \t loss: 7444.499778882083\n",
      "epoch: 368000 \t loss: 7441.466613509705\n",
      "epoch: 369000 \t loss: 7438.437593341554\n",
      "epoch: 370000 \t loss: 7435.412707231053\n",
      "epoch: 371000 \t loss: 7432.39194417645\n",
      "epoch: 372000 \t loss: 7429.375293317629\n",
      "epoch: 373000 \t loss: 7426.362743933031\n",
      "epoch: 374000 \t loss: 7423.354285436608\n",
      "epoch: 375000 \t loss: 7420.349907374876\n",
      "epoch: 376000 \t loss: 7417.349599424046\n",
      "epoch: 377000 \t loss: 7414.353351387164\n",
      "epoch: 378000 \t loss: 7411.36115319139\n",
      "epoch: 379000 \t loss: 7408.372994885301\n",
      "epoch: 380000 \t loss: 7405.3888666362345\n",
      "epoch: 381000 \t loss: 7402.408758727761\n",
      "epoch: 382000 \t loss: 7399.432661557139\n",
      "epoch: 383000 \t loss: 7396.460565632888\n",
      "epoch: 384000 \t loss: 7393.492461572392\n",
      "epoch: 385000 \t loss: 7390.528340099536\n",
      "epoch: 386000 \t loss: 7387.568192042452\n",
      "epoch: 387000 \t loss: 7384.612008331259\n",
      "epoch: 388000 \t loss: 7381.659779995911\n",
      "epoch: 389000 \t loss: 7378.711498164039\n",
      "epoch: 390000 \t loss: 7375.767154058881\n",
      "epoch: 391000 \t loss: 7372.826738997239\n",
      "epoch: 392000 \t loss: 7369.890244387519\n",
      "epoch: 393000 \t loss: 7366.957661727753\n",
      "epoch: 394000 \t loss: 7364.028982603717\n",
      "epoch: 395000 \t loss: 7361.104198687095\n",
      "epoch: 396000 \t loss: 7358.183301733639\n",
      "epoch: 397000 \t loss: 7355.26628358142\n",
      "epoch: 398000 \t loss: 7352.353136149084\n",
      "epoch: 399000 \t loss: 7349.443851434178\n",
      "epoch: 400000 \t loss: 7346.538421511495\n",
      "epoch: 401000 \t loss: 7343.636838531449\n",
      "epoch: 402000 \t loss: 7340.73909471851\n",
      "epoch: 403000 \t loss: 7337.845182369683\n",
      "epoch: 404000 \t loss: 7334.95509385297\n",
      "epoch: 405000 \t loss: 7332.068821605912\n",
      "epoch: 406000 \t loss: 7329.18635813416\n",
      "epoch: 407000 \t loss: 7326.307696010069\n",
      "epoch: 408000 \t loss: 7323.432827871315\n",
      "epoch: 409000 \t loss: 7320.561746419574\n",
      "epoch: 410000 \t loss: 7317.694444419198\n",
      "epoch: 411000 \t loss: 7314.830914695934\n",
      "epoch: 412000 \t loss: 7311.971150135691\n",
      "epoch: 413000 \t loss: 7309.115143683288\n",
      "epoch: 414000 \t loss: 7306.2628883413\n",
      "epoch: 415000 \t loss: 7303.414377168844\n",
      "epoch: 416000 \t loss: 7300.569603280484\n",
      "epoch: 417000 \t loss: 7297.728559845083\n",
      "epoch: 418000 \t loss: 7294.891240084713\n",
      "epoch: 419000 \t loss: 7292.057637273625\n",
      "epoch: 420000 \t loss: 7289.2277447371725\n",
      "epoch: 421000 \t loss: 7286.401555850811\n",
      "epoch: 422000 \t loss: 7283.579064039102\n",
      "epoch: 423000 \t loss: 7280.760262774742\n",
      "epoch: 424000 \t loss: 7277.945145577603\n",
      "epoch: 425000 \t loss: 7275.133706013824\n",
      "epoch: 426000 \t loss: 7272.3259376948845\n",
      "epoch: 427000 \t loss: 7269.521834276731\n",
      "epoch: 428000 \t loss: 7266.721389458905\n",
      "epoch: 429000 \t loss: 7263.9245969837\n",
      "epoch: 430000 \t loss: 7261.131450635328\n",
      "epoch: 431000 \t loss: 7258.341944239112\n",
      "epoch: 432000 \t loss: 7255.556071660705\n",
      "epoch: 433000 \t loss: 7252.773826805299\n",
      "epoch: 434000 \t loss: 7249.995203616885\n",
      "epoch: 435000 \t loss: 7247.220196077505\n",
      "epoch: 436000 \t loss: 7244.448798206533\n",
      "epoch: 437000 \t loss: 7241.6810040599685\n",
      "epoch: 438000 \t loss: 7238.916807729762\n",
      "epoch: 439000 \t loss: 7236.1562033431\n",
      "epoch: 440000 \t loss: 7233.399185061792\n",
      "epoch: 441000 \t loss: 7230.645747081601\n",
      "epoch: 442000 \t loss: 7227.895883631609\n",
      "epoch: 443000 \t loss: 7225.149588973623\n",
      "epoch: 444000 \t loss: 7222.406857401548\n",
      "epoch: 445000 \t loss: 7219.667683240812\n",
      "epoch: 446000 \t loss: 7216.932060847794\n",
      "epoch: 447000 \t loss: 7214.199984609248\n",
      "epoch: 448000 \t loss: 7211.471448941758\n",
      "epoch: 449000 \t loss: 7208.746448291218\n",
      "epoch: 450000 \t loss: 7206.024977132264\n",
      "epoch: 451000 \t loss: 7203.307029967807\n",
      "epoch: 452000 \t loss: 7200.5926013284925\n",
      "epoch: 453000 \t loss: 7197.881685772249\n",
      "epoch: 454000 \t loss: 7195.174277883749\n",
      "epoch: 455000 \t loss: 7192.470372273995\n",
      "epoch: 456000 \t loss: 7189.76996357983\n",
      "epoch: 457000 \t loss: 7187.0730464635\n",
      "epoch: 458000 \t loss: 7184.37961561221\n",
      "epoch: 459000 \t loss: 7181.68966573769\n",
      "epoch: 460000 \t loss: 7179.003191575781\n",
      "epoch: 461000 \t loss: 7176.320187886017\n",
      "epoch: 462000 \t loss: 7173.640649451236\n",
      "epoch: 463000 \t loss: 7170.964571077172\n",
      "epoch: 464000 \t loss: 7168.291947592084\n",
      "epoch: 465000 \t loss: 7165.622773846366\n",
      "epoch: 466000 \t loss: 7162.957044712182\n",
      "epoch: 467000 \t loss: 7160.294755083125\n",
      "epoch: 468000 \t loss: 7157.635899873836\n",
      "epoch: 469000 \t loss: 7154.980474019687\n",
      "epoch: 470000 \t loss: 7152.3284724764235\n",
      "epoch: 471000 \t loss: 7149.6798902198525\n",
      "epoch: 472000 \t loss: 7147.034722245502\n",
      "epoch: 473000 \t loss: 7144.392963568327\n",
      "epoch: 474000 \t loss: 7141.754609222378\n",
      "epoch: 475000 \t loss: 7139.119654260534\n",
      "epoch: 476000 \t loss: 7136.488093754158\n",
      "epoch: 477000 \t loss: 7133.859922792864\n",
      "epoch: 478000 \t loss: 7131.235136484191\n",
      "epoch: 479000 \t loss: 7128.61372995335\n",
      "epoch: 480000 \t loss: 7125.99569834295\n",
      "epoch: 481000 \t loss: 7123.381036812726\n",
      "epoch: 482000 \t loss: 7120.769740539295\n",
      "epoch: 483000 \t loss: 7118.1618047158845\n",
      "epoch: 484000 \t loss: 7115.557224552108\n",
      "epoch: 485000 \t loss: 7112.955995273705\n",
      "epoch: 486000 \t loss: 7110.358112122309\n",
      "epoch: 487000 \t loss: 7107.763570355219\n",
      "epoch: 488000 \t loss: 7105.172365245171\n",
      "epoch: 489000 \t loss: 7102.584492080115\n",
      "epoch: 490000 \t loss: 7099.999946162996\n",
      "epoch: 491000 \t loss: 7097.418722811557\n",
      "epoch: 492000 \t loss: 7094.840817358112\n",
      "epoch: 493000 \t loss: 7092.26622514934\n",
      "epoch: 494000 \t loss: 7089.694941546115\n",
      "epoch: 495000 \t loss: 7087.126961923277\n",
      "epoch: 496000 \t loss: 7084.562281669462\n",
      "epoch: 497000 \t loss: 7082.000896186917\n",
      "epoch: 498000 \t loss: 7079.4428008913\n",
      "epoch: 499000 \t loss: 7076.8879912115135\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoches):\n",
    "    delta_w = lr * np.dot(x_train.T, error)\n",
    "    delta_b = lr* error.sum()\n",
    "    \n",
    "    w = w - delta_w / m\n",
    "    b = b - delta_b / m\n",
    "    \n",
    "    hat_y = np.dot(x_train, w) + b * np.ones_like(x_train.shape[0])\n",
    "    error = hat_y - y_train.reshape(-1, 1)\n",
    "    \n",
    "    loss = 0.5 * error ** 2\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"epoch: {epoch} \\t loss: {loss.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = lambda num: (np.dot(x_test[num, :], w) + b, y_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([22.87754994]), 19.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([24.01166513]), 22.2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([21.23986411]), 21.2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num(63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([21.40267385]), 28.1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num(77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
